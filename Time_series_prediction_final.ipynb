{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6mNz7V5W2s3n"
   },
   "source": [
    "---\n",
    "<div style=\"text-align: center;\">\n",
    "  <h1>Project: Time Series Prediction</h1>\n",
    "</div>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o3uQk9Ox38gx"
   },
   "source": [
    "# 0. Thông tin chung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AcCLzw204F5K"
   },
   "source": [
    "## 0.1. Đặt vấn đề"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "30KR_JraGJxH"
   },
   "source": [
    "<div style=\"text-align: justify\">\n",
    "Hiện nay, với sự phát triển không ngừng của các hệ thống dịch vụ và ứng dụng công nghệ thông tin, yêu cầu về tính ổn định và sẵn sàng của các hệ thống trở nên ngày càng quan trọng. Bất kỳ sự cố nào xảy ra trong một phần của hệ thống đều có thể gây ra gián đoạn cho toàn bộ dịch vụ, ảnh hưởng đến trải nghiệm người dùng và gây tổn thất kinh tế. Đặc biệt, trong những hệ thống phức tạp, lỗi có thể xảy ra không chỉ do các yếu tố bên ngoài mà còn có thể xuất phát từ sự tương tác giữa các service, tạo nên một vấn đề nan giải cho công tác quản lý và bảo trì.\n",
    "\n",
    "Việc dự báo trước các lỗi hệ thống là một nhiệm vụ quan trọng nhằm tăng cường tính ổn định và tối ưu hóa hiệu quả vận hành. Nếu có thể dự đoán chính xác lỗi có thể xảy ra và xác định cụ thể lỗi đó thuộc về service nào, đội ngũ kỹ thuật có thể thực hiện các biện pháp khắc phục sớm, giảm thiểu tối đa các thiệt hại và duy trì chất lượng dịch vụ ở mức cao nhất. Có nhiều phương pháp dự đoán lỗi hệ thống, từ các mô hình hồi quy thống kê đến các mô hình machine learning. Trong đó, các mô hình học máy nổi bật với khả năng xử lý các tập dữ liệu phức tạp, xác định các mối quan hệ phi tuyến tính và cải thiện độ chính xác của dự báo.\n",
    "\n",
    "Nhiều nghiên cứu đã chứng minh tính hiệu quả của mô hình học máy trong dự đoán lỗi hệ thống. Một số nghiên cứu cho thấy việc áp dụng các mô hình học máy như Random Forest, XGBoost, LSTM, hay CNN có thể đạt độ chính xác cao trong dự báo các sự cố hệ thống và rút ngắn thời gian phản hồi, giúp các hệ thống ứng dụng và dịch vụ vận hành mượt mà hơn. Tuy nhiên, tại Việt Nam, nghiên cứu về dự đoán lỗi trong hệ thống dịch vụ chưa được khai thác rộng rãi. Vì vậy, đề tài sẽ áp dụng mô hình học máy để dự đoán lỗi trong hệ thống dịch vụ tại một thời điểm nhất định và dự báo xem lỗi sẽ xảy ra ở service nào, từ đó cung cấp các cảnh báo sớm và hỗ trợ công tác bảo trì hiệu quả.\n",
    "</div>\n",
    "\n",
    "**Mục tiêu chính của đề tài bao gồm:**\n",
    "\n",
    "* **Xử lý dữ liệu và xây dựng thuật toán bằng ngôn ngữ Python**\n",
    "\n",
    "* **Dự báo lỗi trong vòng 2 giờ sau một mốc thời gian cụ thể**\n",
    "\n",
    "* **Xác định service cụ thể có khả năng gặp sự cố**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nIjZzUoz4Rc7"
   },
   "source": [
    "## 0.2. Danh sách thành viên\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6e5Gj6hrQZUK"
   },
   "source": [
    "|    Họ và tên    |  MSSV   |  Ghi chú  |\n",
    "|-----------------|---------|-----------|\n",
    "|Ngô Trần Quốc Bảo|22280004 |           |\n",
    "|Phan Nhị Hào     |22280019 |           |\n",
    "|Đào Vĩnh Khang   |22280030 |           |\n",
    "|Võ Xuân Lộc      |22280040 |           |\n",
    "|Nguyễn Hoàng Ngân|22280045 |Nhóm trưởng|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YIKXryKCGd3Z"
   },
   "source": [
    "# 1. Giới thiệu Dataset (0.5 điểm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nD2H7jRDHqp8"
   },
   "source": [
    "## a. Kích thước dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ripWy4qYhUJd"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = 'D:\\\\1 Co so khoa hoc du lieu\\\\clean_feature.csv'\n",
    "data = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "IuDkkNHChUJd",
    "outputId": "cd8a8b8d-ccb4-4276-beae-f7b4da5c4e89"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Day</th>\n",
       "      <th>DoWeek</th>\n",
       "      <th>hour</th>\n",
       "      <th>count</th>\n",
       "      <th>passed</th>\n",
       "      <th>period</th>\n",
       "      <th>data</th>\n",
       "      <th>ServiceID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-12-29</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>2974</td>\n",
       "      <td>2974</td>\n",
       "      <td>63.952589</td>\n",
       "      <td>612.081036</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-12-29</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>4528</td>\n",
       "      <td>4528</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>960.307862</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-12-29</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>566.315789</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-12-29</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>1207</td>\n",
       "      <td>1207</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>601.025684</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-12-29</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>8450</td>\n",
       "      <td>8450</td>\n",
       "      <td>63.942130</td>\n",
       "      <td>611.024024</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450666</th>\n",
       "      <td>2023-07-24</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>624.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450667</th>\n",
       "      <td>2023-07-24</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>108</td>\n",
       "      <td>108</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>1075.972222</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450668</th>\n",
       "      <td>2023-07-24</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>5279</td>\n",
       "      <td>5279</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>599.900170</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450669</th>\n",
       "      <td>2023-07-24</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>1437.500000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450670</th>\n",
       "      <td>2023-07-24</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>378255.166667</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>450671 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Day  DoWeek  hour  count  passed     period           data  \\\n",
       "0       2021-12-29       2    17   2974    2974  63.952589     612.081036   \n",
       "1       2021-12-29       2    17   4528    4528  63.000000     960.307862   \n",
       "2       2021-12-29       2    17     19      19  62.000000     566.315789   \n",
       "3       2021-12-29       2    17   1207    1207  63.000000     601.025684   \n",
       "4       2021-12-29       2    18   8450    8450  63.942130     611.024024   \n",
       "...            ...     ...   ...    ...     ...        ...            ...   \n",
       "450666  2023-07-24       0    18      1       1  62.000000     624.000000   \n",
       "450667  2023-07-24       0    18    108     108  62.000000    1075.972222   \n",
       "450668  2023-07-24       0    18   5279    5279  63.000000     599.900170   \n",
       "450669  2023-07-24       0    18      2       2  63.000000    1437.500000   \n",
       "450670  2023-07-24       0    18     18      18   0.000000  378255.166667   \n",
       "\n",
       "        ServiceID  \n",
       "0               2  \n",
       "1              11  \n",
       "2               5  \n",
       "3               7  \n",
       "4               2  \n",
       "...           ...  \n",
       "450666          1  \n",
       "450667          5  \n",
       "450668          7  \n",
       "450669          0  \n",
       "450670         10  \n",
       "\n",
       "[450671 rows x 8 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QyTx1lq2Ht7t"
   },
   "source": [
    "## b. Ý nghĩa mỗi cột/hàng"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1im13Z98Qc_0"
   },
   "source": [
    "Mỗi cột trong data set có ý nghĩa như sau:\n",
    "|   Tên   |Ý nghĩa|\n",
    "|---------|-----|\n",
    "|Day      |Thời điểm thu thập dữ liệu (YYYY-MM-DD)|\n",
    "|DoWeek   |Ngày trong tuần (từ 0 đến 7)|\n",
    "|hour     |Giờ trong ngày mà dữ liệu ghi nhận (từ 0 đến 23)|\n",
    "|count    |Số lượng yêu cầu được ghi nhận tại thời điểm đó|\n",
    "|passed   |Số lượng yêu cầu được hoàn thành thành công|\n",
    "|period   |Khoảng thời gian xử lý yêu cầu|\n",
    "|data     |Khối lượng dữ liệu được xử lý|\n",
    "|ServiceID|Mã định danh của Service (từ 0 đến 11)|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ab4PlwW0hUJe"
   },
   "source": [
    "Mỗi hàng trong dataset đại diện cho một bản ghi (record) vào một thời điểm cụ thể cho một service trong hệ thống, bao gồm thông tin chi tiết về ngày giờ, lưu lượng yêu cầu, hiệu suất xử lý và lượng dữ liệu truyền tải."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tetQfJuphUJe"
   },
   "source": [
    "# 2. Giới thiệu vấn đề muốn giải quyết (0.5 điểm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "onwEF1aUhUJe"
   },
   "source": [
    "<div style=\"text-align: justify\">\n",
    "Trong các hệ thống dịch vụ phức tạp, lỗi có thể xuất hiện bất ngờ và gây ảnh hưởng nghiêm trọng đến hiệu suất, trải nghiệm người dùng và các chỉ số vận hành của hệ thống. Để giảm thiểu tác động tiêu cực này, việc dự đoán các lỗi có thể xảy ra trong tương lai gần, chẳng hạn như trong hai giờ sau một thời điểm xác định, là rất cần thiết. Bài toán này đặt ra mục tiêu phát hiện sớm các dịch vụ có khả năng gặp sự cố dựa trên các thông tin ghi nhận về hoạt động hệ thống ở thời điểm hiện tại.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dDwTN6OGhUJe"
   },
   "source": [
    "## a. Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "7M7XEXFChUJe"
   },
   "outputs": [],
   "source": [
    "data = data.copy()\n",
    "data['Day'] = pd.to_datetime(data['Day'], errors='coerce')\n",
    "data['Datetime'] = data.apply(lambda row: row['Day'] + pd.Timedelta(hours=row['hour']), axis=1)\n",
    "data['error_flag'] = (data['count'] - data['passed']) != 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "fcCBVrYqhUJe",
    "outputId": "ac1c3805-b377-4df6-e9d0-5e870139381a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Day</th>\n",
       "      <th>DoWeek</th>\n",
       "      <th>hour</th>\n",
       "      <th>count</th>\n",
       "      <th>passed</th>\n",
       "      <th>period</th>\n",
       "      <th>data</th>\n",
       "      <th>ServiceID</th>\n",
       "      <th>Datetime</th>\n",
       "      <th>error_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-12-29</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>2974</td>\n",
       "      <td>2974</td>\n",
       "      <td>63.952589</td>\n",
       "      <td>612.081036</td>\n",
       "      <td>2</td>\n",
       "      <td>2021-12-29 17:00:00</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-12-29</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>4528</td>\n",
       "      <td>4528</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>960.307862</td>\n",
       "      <td>11</td>\n",
       "      <td>2021-12-29 17:00:00</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-12-29</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>566.315789</td>\n",
       "      <td>5</td>\n",
       "      <td>2021-12-29 17:00:00</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-12-29</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>1207</td>\n",
       "      <td>1207</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>601.025684</td>\n",
       "      <td>7</td>\n",
       "      <td>2021-12-29 17:00:00</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-12-29</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>8450</td>\n",
       "      <td>8450</td>\n",
       "      <td>63.942130</td>\n",
       "      <td>611.024024</td>\n",
       "      <td>2</td>\n",
       "      <td>2021-12-29 18:00:00</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Day  DoWeek  hour  count  passed     period        data  ServiceID  \\\n",
       "0 2021-12-29       2    17   2974    2974  63.952589  612.081036          2   \n",
       "1 2021-12-29       2    17   4528    4528  63.000000  960.307862         11   \n",
       "2 2021-12-29       2    17     19      19  62.000000  566.315789          5   \n",
       "3 2021-12-29       2    17   1207    1207  63.000000  601.025684          7   \n",
       "4 2021-12-29       2    18   8450    8450  63.942130  611.024024          2   \n",
       "\n",
       "             Datetime  error_flag  \n",
       "0 2021-12-29 17:00:00       False  \n",
       "1 2021-12-29 17:00:00       False  \n",
       "2 2021-12-29 17:00:00       False  \n",
       "3 2021-12-29 17:00:00       False  \n",
       "4 2021-12-29 18:00:00       False  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j_vhzak1hUJe"
   },
   "source": [
    "T: Mốc thời điểm cụ thể trong lịch sử hoạt động của hệ thống mà chúng ta muốn dự báo.\n",
    "ΔT: Khoảng thời gian quan sát trước mốc thời gian T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "JzizDwDPhUJe"
   },
   "outputs": [],
   "source": [
    "# Nhập mốc thời gian T và chuyển sang dạng datetime\n",
    "user_input = \"2023-01-23 23\" # T tự chọn\n",
    "T = pd.to_datetime(user_input, format='%Y-%m-%d %H')\n",
    "\n",
    "# Mốc thời gian ΔT (số giờ muốn quan sát)\n",
    "deltaT = int(12) # ΔT tự chọn\n",
    "T_start = T - pd.to_timedelta(deltaT, unit='h')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YMni9fVkhUJe"
   },
   "source": [
    "## b. Ouput: Các dịch vụ bị lỗi tại thời điểm T+2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ugMoqGhIhUJf"
   },
   "source": [
    "Danh sách các dịch vụ bị lỗi tại thời điểm T+2: Dự báo các service dự kiến sẽ gặp lỗi trong hai giờ sau thời điểm T.\n",
    "\n",
    "Mục tiêu: Cung cấp một danh sách các service tiềm năng gặp sự cố để đội ngũ kỹ thuật có thể phản ứng kịp thời và triển khai các biện pháp xử lý trước khi lỗi xảy ra.\n",
    "\n",
    "Danh sách này được thể hiện dưới dạng vector. Ví dụ nếu kết quả là [010001101100] tức là Service bị lỗi có ID: 1, 5, 6, 8, 9."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Brd-taERhUJf"
   },
   "source": [
    "# 3. Giới thiệu về cách train/test split (0.5 điểm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RyfgCQd9hUJf"
   },
   "source": [
    "## a. Tổng quan dữ liệu thu được"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iMWdcRb6hUJf"
   },
   "source": [
    "Thời gian thu thập dữ liệu trong 2 năm: Từ ngày 29/12/2021 đến ngày 4/8/2023."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "ODduDzIWhUJf",
    "outputId": "02e81665-5690-4ebb-b8a9-507630664d19"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thời điểm bắt đầu lấy dữ liệu: 2021-12-29 17:00:00\n",
      "Thời điểm kết thúc lấy dữ liệu: 2023-08-04 18:00:00\n"
     ]
    }
   ],
   "source": [
    "# Xác định ngày bắt đầu và kết thúc trong dataset\n",
    "start_date = data['Datetime'].min()\n",
    "end_date = data['Datetime'].max()\n",
    "\n",
    "# In ra ngày và giờ bắt đầu và kết thúc\n",
    "print(\"Thời điểm bắt đầu lấy dữ liệu:\", start_date.strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "print(\"Thời điểm kết thúc lấy dữ liệu:\", end_date.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4_gpHfqOhUJf"
   },
   "source": [
    "## b. Chia bộ dữ liệu train/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "eywZo1V0hUJf",
    "outputId": "1e21427e-6d84-4d04-c1aa-e8700a174d39"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(443011, 10)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loại bỏ các hàng trùng lặp\n",
    "data = data.drop_duplicates()\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "S7XYGks3hUJf",
    "outputId": "f4c02542-0a0f-4cfe-932f-ff83968fe0c5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tập train có 277670 bản ghi từ 2021-12-29 17:00:00 đến 2023-01-23 23:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tập test có 165341 bản ghi từ 2023-01-24 00:00:00 đến 2023-08-04 18:00:00\n"
     ]
    }
   ],
   "source": [
    "train_data = data[data['Datetime'] <= T]\n",
    "test_data = data[data['Datetime'] > T]\n",
    "\n",
    "# Kiểm tra kết quả\n",
    "print(f\"Tập train có {len(train_data)} bản ghi từ {train_data['Datetime'].min()} đến {train_data['Datetime'].max()}\")\n",
    "print(f\"Tập test có {len(test_data)} bản ghi từ {test_data['Datetime'].min()} đến {test_data['Datetime'].max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5me6iHGQGcoR"
   },
   "source": [
    "# 4. Giới thiệu về observation trong khoảng thời gian từ T-ΔT đến T (1 điểm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PZeyeeaGhUJg"
   },
   "source": [
    "## a. Cách lấy observation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0KWIM-XwhUJg"
   },
   "source": [
    "Cho ΔT và T nhập từ bàn phím. Khi đó quãng thời gian từ T-ΔT đến T được coi là quãng thời gian quan sát để thu thập dữ liệu, từ dữ liệu này ta xử lý để đưa vào train model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "IHntuStrhUJg",
    "outputId": "6ef59a2b-dff9-4292-efdf-6e889e5062fe"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Day</th>\n",
       "      <th>DoWeek</th>\n",
       "      <th>hour</th>\n",
       "      <th>count</th>\n",
       "      <th>passed</th>\n",
       "      <th>period</th>\n",
       "      <th>data</th>\n",
       "      <th>ServiceID</th>\n",
       "      <th>Datetime</th>\n",
       "      <th>error_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>69679</th>\n",
       "      <td>2023-01-23</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>5557</td>\n",
       "      <td>5557</td>\n",
       "      <td>63.867195</td>\n",
       "      <td>611.024114</td>\n",
       "      <td>2</td>\n",
       "      <td>2023-01-23 11:00:00</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69680</th>\n",
       "      <td>2023-01-23</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>7892</td>\n",
       "      <td>7892</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>899.349975</td>\n",
       "      <td>11</td>\n",
       "      <td>2023-01-23 11:00:00</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69681</th>\n",
       "      <td>2023-01-23</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>301.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-01-23 11:00:00</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69682</th>\n",
       "      <td>2023-01-23</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>873.858586</td>\n",
       "      <td>5</td>\n",
       "      <td>2023-01-23 11:00:00</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69683</th>\n",
       "      <td>2023-01-23</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>2110</td>\n",
       "      <td>2110</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>599.821327</td>\n",
       "      <td>7</td>\n",
       "      <td>2023-01-23 11:00:00</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407635</th>\n",
       "      <td>2023-01-23</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>597.833333</td>\n",
       "      <td>7</td>\n",
       "      <td>2023-01-23 23:00:00</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407636</th>\n",
       "      <td>2023-01-23</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>2906</td>\n",
       "      <td>2906</td>\n",
       "      <td>63.810048</td>\n",
       "      <td>590.590158</td>\n",
       "      <td>2</td>\n",
       "      <td>2023-01-23 23:00:00</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407637</th>\n",
       "      <td>2023-01-23</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>4285</td>\n",
       "      <td>4285</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>888.803267</td>\n",
       "      <td>11</td>\n",
       "      <td>2023-01-23 23:00:00</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407638</th>\n",
       "      <td>2023-01-23</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>81</td>\n",
       "      <td>81</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>4216.975309</td>\n",
       "      <td>5</td>\n",
       "      <td>2023-01-23 23:00:00</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407639</th>\n",
       "      <td>2023-01-23</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>1733</td>\n",
       "      <td>1733</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>599.145990</td>\n",
       "      <td>7</td>\n",
       "      <td>2023-01-23 23:00:00</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>289 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Day  DoWeek  hour  count  passed     period         data  \\\n",
       "69679  2023-01-23       0    11   5557    5557  63.867195   611.024114   \n",
       "69680  2023-01-23       0    11   7892    7892  63.000000   899.349975   \n",
       "69681  2023-01-23       0    11     13      13  62.000000   301.000000   \n",
       "69682  2023-01-23       0    11     99      99  62.000000   873.858586   \n",
       "69683  2023-01-23       0    11   2110    2110  63.000000   599.821327   \n",
       "...           ...     ...   ...    ...     ...        ...          ...   \n",
       "407635 2023-01-23       0    23     42      42  63.000000   597.833333   \n",
       "407636 2023-01-23       0    23   2906    2906  63.810048   590.590158   \n",
       "407637 2023-01-23       0    23   4285    4285  63.000000   888.803267   \n",
       "407638 2023-01-23       0    23     81      81  62.000000  4216.975309   \n",
       "407639 2023-01-23       0    23   1733    1733  63.000000   599.145990   \n",
       "\n",
       "        ServiceID            Datetime  error_flag  \n",
       "69679           2 2023-01-23 11:00:00       False  \n",
       "69680          11 2023-01-23 11:00:00       False  \n",
       "69681           1 2023-01-23 11:00:00       False  \n",
       "69682           5 2023-01-23 11:00:00       False  \n",
       "69683           7 2023-01-23 11:00:00       False  \n",
       "...           ...                 ...         ...  \n",
       "407635          7 2023-01-23 23:00:00       False  \n",
       "407636          2 2023-01-23 23:00:00       False  \n",
       "407637         11 2023-01-23 23:00:00       False  \n",
       "407638          5 2023-01-23 23:00:00       False  \n",
       "407639          7 2023-01-23 23:00:00       False  \n",
       "\n",
       "[289 rows x 10 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lọc dữ liệu trong khoảng từ T_start đến T\n",
    "filtered_data = data[(data['Datetime'] >= T_start) & (data['Datetime'] <= T)]\n",
    "filtered_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5nsgGhkkhUJg"
   },
   "source": [
    "## b. Kích thước observation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IzzUaE4ihUJg"
   },
   "source": [
    "Kích thước của observation sẽ phụ thuộc vào số lượng hàng và cột trong bộ dữ liệu từ T-ΔT đến T. Lúc này kích thước sẽ phụ thuộc vào ΔT và T."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "7Pnbn0l8hUJg",
    "outputId": "3771e4c3-4efb-4c4d-9a27-8377e74467fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kích thước observation từ 2023-01-23 11:00:00 đến 2023-01-23 23:00:00 là: 289 hàng và 10 cột\n"
     ]
    }
   ],
   "source": [
    "# In ra số lượng hàng trong filtered_data\n",
    "r, c = filtered_data.shape\n",
    "print(f\"Kích thước observation từ {T_start} đến {T} là: {r} hàng và {c} cột\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gHN9JNfQhUJg"
   },
   "source": [
    "## c. Số lượng hàng và cột"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FuUN3iadhUJg"
   },
   "source": [
    "Bởi phụ thuộc vào Tvà ΔT, số lượng hàng không cố định. Số lượng hàng sẽ là số hàng dữ liệu trong bộ dữ liệu từ T-ΔT đến T."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "ZPU6Vp8ohUJk",
    "outputId": "b1800053-37f3-4414-accd-24509711ad8c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Với T = 2023-05-02 23:00:00 và ΔT = 1 giờ, số lượng hàng trong filtered_data là: 38\n",
      "Với T = 2023-05-02 23:00:00 và ΔT = 6 giờ, số lượng hàng trong filtered_data là: 185\n",
      "Với T = 2023-05-02 23:00:00 và ΔT = 10 giờ, số lượng hàng trong filtered_data là: 323\n",
      "Với T = 2023-05-02 23:00:00 và ΔT = 24 giờ, số lượng hàng trong filtered_data là: 655\n"
     ]
    }
   ],
   "source": [
    "# Thử nghiệm với các giá trị ΔT và T khác nhau để chứng minh sự phụ thuộc\n",
    "# Thay đổi ΔT và T để so sánh\n",
    "deltaT_values = [1, 6, 10, 24]  # Các giá trị ΔT khác nhau (giờ)\n",
    "T_values = \"2023-05-02 23\"  # Thời điểm T khác trước đó\n",
    "T_test = pd.to_datetime(T_values, format='%Y-%m-%d %H')\n",
    "\n",
    "for deltaT_test in deltaT_values:\n",
    "    T_start_test = T_test - pd.to_timedelta(deltaT_test, unit='h')\n",
    "\n",
    "    # Lọc dữ liệu với giá trị T và ΔT hiện tại\n",
    "    filtered_data_test = data[(data['Datetime'] >= T_start_test) & (data['Datetime'] <= T_test)]\n",
    "    r, c = filtered_data_test.shape\n",
    "    print(f\"Với T = {T_test} và ΔT = {deltaT_test} giờ, số lượng hàng trong filtered_data là: {r}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4XmFrHrQhUJk"
   },
   "source": [
    "Số lượng cột sẽ luôn cố định là 10 - số lượng features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "xpIs4S4YhUJk",
    "outputId": "1e0df4f6-80ac-4646-a05d-d32b7827f6a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Với T = 2023-05-02 23:00:00 và ΔT = 1 giờ, số lượng cột trong filtered_data là: 10\n",
      "Với T = 2023-05-02 23:00:00 và ΔT = 6 giờ, số lượng cột trong filtered_data là: 10\n",
      "Với T = 2023-05-02 23:00:00 và ΔT = 10 giờ, số lượng cột trong filtered_data là: 10\n",
      "Với T = 2023-05-02 23:00:00 và ΔT = 24 giờ, số lượng cột trong filtered_data là: 10\n"
     ]
    }
   ],
   "source": [
    "for deltaT_test in deltaT_values:\n",
    "    print(f\"Với T = {T_test} và ΔT = {deltaT_test} giờ, số lượng cột trong filtered_data là: {c}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-gEwcorThUJk"
   },
   "source": [
    "## d. Chuyển đặc trưng về dạng vector số"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xYzN3YA_hUJk",
    "outputId": "e54a304b-6816-48a9-ce4e-272240bbaf88"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     period_service_0  period_service_1  period_service_2  \\\n",
      "Datetime                                                                    \n",
      "2021-12-29 17:00:00           0.00000               0.0          0.678733   \n",
      "2021-12-29 18:00:00           0.00000               0.0          0.548889   \n",
      "2021-12-29 19:00:00           0.00000               0.0          0.605706   \n",
      "2021-12-29 20:00:00           0.00000               0.0          0.518420   \n",
      "2021-12-29 21:00:00           0.01184               0.0          0.461040   \n",
      "\n",
      "                     period_service_3  period_service_4  period_service_5  \\\n",
      "Datetime                                                                    \n",
      "2021-12-29 17:00:00          0.000000               0.0          0.005647   \n",
      "2021-12-29 18:00:00          0.000000               0.0          0.005647   \n",
      "2021-12-29 19:00:00          0.000000               0.0          0.005647   \n",
      "2021-12-29 20:00:00          0.000000               0.0          0.005647   \n",
      "2021-12-29 21:00:00         -0.222256               0.0          0.005647   \n",
      "\n",
      "                     period_service_6  period_service_7  period_service_8  \\\n",
      "Datetime                                                                    \n",
      "2021-12-29 17:00:00               0.0          0.023157               0.0   \n",
      "2021-12-29 18:00:00               0.0          0.023157               0.0   \n",
      "2021-12-29 19:00:00               0.0          0.023157               0.0   \n",
      "2021-12-29 20:00:00               0.0          0.023157               0.0   \n",
      "2021-12-29 21:00:00               0.0          0.023157               0.0   \n",
      "\n",
      "                     period_service_9  ...  error_service_2  error_service_3  \\\n",
      "Datetime                               ...                                     \n",
      "2021-12-29 17:00:00               0.0  ...              0.0              0.0   \n",
      "2021-12-29 18:00:00               0.0  ...              0.0              0.0   \n",
      "2021-12-29 19:00:00               0.0  ...              0.0              0.0   \n",
      "2021-12-29 20:00:00               0.0  ...              0.0              0.0   \n",
      "2021-12-29 21:00:00               0.0  ...              0.0              1.0   \n",
      "\n",
      "                     error_service_4  error_service_5  error_service_6  \\\n",
      "Datetime                                                                 \n",
      "2021-12-29 17:00:00              0.0              0.0              0.0   \n",
      "2021-12-29 18:00:00              0.0              0.0              0.0   \n",
      "2021-12-29 19:00:00              0.0              0.0              0.0   \n",
      "2021-12-29 20:00:00              0.0              0.0              0.0   \n",
      "2021-12-29 21:00:00              0.0              0.0              0.0   \n",
      "\n",
      "                     error_service_7  error_service_8  error_service_9  \\\n",
      "Datetime                                                                 \n",
      "2021-12-29 17:00:00              0.0              0.0              0.0   \n",
      "2021-12-29 18:00:00              0.0              0.0              0.0   \n",
      "2021-12-29 19:00:00              0.0              0.0              0.0   \n",
      "2021-12-29 20:00:00              0.0              0.0              0.0   \n",
      "2021-12-29 21:00:00              0.0              0.0              0.0   \n",
      "\n",
      "                     error_service_10  error_service_11  \n",
      "Datetime                                                 \n",
      "2021-12-29 17:00:00               0.0               0.0  \n",
      "2021-12-29 18:00:00               0.0               0.0  \n",
      "2021-12-29 19:00:00               0.0               0.0  \n",
      "2021-12-29 20:00:00               0.0               0.0  \n",
      "2021-12-29 21:00:00               0.0               0.0  \n",
      "\n",
      "[5 rows x 73 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Giữ nguyên bước xử lý dữ liệu ban đầu\n",
    "data['error_flag'] = data['error_flag'].astype(int)\n",
    "data = data.groupby(['Datetime', 'ServiceID']).agg({      \n",
    "    'period': 'mean',\n",
    "    'data': 'mean',\n",
    "    'DoWeek': 'mean',  # Dữ liệu `DoWeek` nguyên bản\n",
    "    'hour': 'mean',\n",
    "    'count': 'mean',\n",
    "    'passed': 'mean',\n",
    "    'error_flag': 'max'\n",
    "}).reset_index()\n",
    "\n",
    "# Tạo pivot table cho `error_flag`\n",
    "error_data = data.pivot(index='Datetime', columns='ServiceID', values='error_flag').fillna(0)\n",
    "error_data.columns = [f\"error_service_{int(col)}\" for col in error_data.columns]\n",
    "\n",
    "# Tạo pivot tables cho các đặc trưng khác, không bao gồm `DoWeek`\n",
    "pivot_tables = {\n",
    "    feature: data.pivot(index='Datetime', columns='ServiceID', values=feature).rename(\n",
    "        columns=lambda x: f\"{feature}_service_{int(x)}\"\n",
    "    )\n",
    "    for feature in ['period', 'data', 'hour', 'count', 'passed']\n",
    "}\n",
    "\n",
    "# Kết hợp tất cả các pivot tables lại\n",
    "vectorized_data = pd.concat(list(pivot_tables.values()) + [error_data], axis=1)\n",
    "\n",
    "# Thêm lại cột `DoWeek` nguyên bản từ `data`\n",
    "doweek_original = data[['Datetime', 'DoWeek']].drop_duplicates().set_index('Datetime')\n",
    "vectorized_data = vectorized_data.join(doweek_original, how='left')\n",
    "\n",
    "# Chuẩn hóa các đặc trưng, không chuẩn hóa `error_service_X`\n",
    "scaler = StandardScaler()\n",
    "features_only = vectorized_data.drop(columns=error_data.columns)\n",
    "features_scaled = pd.DataFrame(scaler.fit_transform(features_only), columns=features_only.columns, index=vectorized_data.index)\n",
    "\n",
    "# Kết hợp lại các đặc trưng đã chuẩn hóa và `error_service_X`\n",
    "vectorized_data_scaled = pd.concat([features_scaled, error_data], axis=1)\n",
    "vectorized_data_scaled.fillna(0, inplace=True)\n",
    "print(vectorized_data_scaled.head())\n",
    "\n",
    "# Tách `train_data` và `test_data` dựa vào thời gian `T`\n",
    "train_data = vectorized_data_scaled[vectorized_data_scaled.index <= T]\n",
    "test_data = vectorized_data_scaled[vectorized_data_scaled.index > T]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EM6wqrp9hUJk"
   },
   "source": [
    "# 5. Giới thiệu về label (1 điểm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J03sOnAFhUJk"
   },
   "source": [
    "## a. Cách sử dụng multi-label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9HPSxU-qhUJk"
   },
   "source": [
    "<div style=\"text-align: justify\">\n",
    "\n",
    "**Giới thiệu về multi-label trong bài toán time-series:** Với bài toán này, ta sẽ xem xét multi-label classification. Mỗi mốc thời gian sẽ có nhiều nhãn đại diện cho từng dịch vụ có lỗi (hoặc không) xảy ra trong khoảng 2 giờ tới. Vì có nhiều ServiceID khác nhau, chúng ta có thể gán một nhãn nhị phân cho từng dịch vụ (0: không lỗi, 1: có lỗi) tại mỗi mốc thời gian.\n",
    "\n",
    "**Cách xây dựng nhãn (label)**\n",
    "\n",
    "- Phân đoạn thời gian: Với mỗi mốc thời gian hiện tại, kiểm tra xem trong 2 giờ tiếp theo, service có lỗi xảy ra hay không.\n",
    "- Gán nhãn: Tạo một cột nhãn multi-label cho từng khung giờ, trong đó mỗi nhãn tương ứng với một service có thể xảy ra lỗi trong 2 giờ tới.\n",
    "Ví dụ, một nhãn [0, 1, 0, ...] nghĩa là trong 2 giờ tới chỉ có service thứ hai gặp lỗi.\n",
    "\n",
    "**Áp dụng multi-label classification**\n",
    "\n",
    "- Chuẩn bị dữ liệu đầu vào: Với mỗi điểm thời gian, tổng hợp thông tin về các service trong 2 giờ tới.\n",
    "- Mô hình hoá: Sử dụng các mô hình để huấn luyện mô hình dự đoán lỗi cho từng service. Mô hình sẽ dự đoán đồng thời nhiều nhãn cho mỗi bản ghi thời gian, giúp xác định tất cả các lỗi có thể xảy ra cho từng service trong khoảng thời gian yêu cầu.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uc3dJcobhUJk"
   },
   "source": [
    "## b. Giới thiệu Neural Network với sigmoid activation ở ngõ ra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KBysvF2ThUJl"
   },
   "source": [
    "<div style=\"text-align: justify\">\n",
    "Neural Network với hàm kích hoạt sigmoid ở ngõ ra (output layer) là một dạng mạng neural sử dụng hàm sigmoid để biến đổi giá trị của các đầu ra về khoảng giá trị từ 0 đến 1. Đây là lựa chọn phù hợp cho các bài toán multi-label, nơi các đầu ra biểu diễn xác suất một sự kiện có thể xảy ra hay không.\n",
    "\n",
    "**Giới thiệu về hàm sigmoid trong mạng neural:** Một hàm kích hoạt đưa mọi đầu vào về giá trị trong khoảng từ 0 đến 1, theo công thức:\n",
    "</div>\n",
    "\n",
    "$$\n",
    "0 \\leq \\sigma(x) \\leq 1\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\sigma(x) = \\frac{1}{1 + e^{-x}} = \\frac{1}{1 + \\frac{1}{e^x}} = \\frac{e^x}{e^x + 1}\n",
    "$$\n",
    "\n",
    "<div style=\"text-align: justify\">\n",
    "Với các đầu ra nằm trong khoảng này, sigmoid phù hợp để biểu diễn xác suất, giúp mạng neural dự đoán nhãn với xác suất cao hơn cho các lớp có khả năng xảy ra.\n",
    "\n",
    "\n",
    "**Ưu điểm của sigmoid ở ngõ ra:**  Multi-label classification: Trong bài toán nhiều nhãn, mỗi nhãn có một đầu ra riêng, và sigmoid sẽ giúp xác định xác suất cho từng nhãn độc lập, phù hợp khi mỗi bản ghi có thể chứa nhiều nhãn cùng lúc.\n",
    "\n",
    "**Ứng dụng sigmoid activation trong dự đoán lỗi:** Với một bài toán multi-label time-series như dự đoán lỗi của nhiều dịch vụ, tại mỗi mốc thời gian, mạng neural có thể dùng các ngõ ra sigmoid để dự đoán xác suất mỗi service có lỗi xảy ra trong 2 giờ tới. Đầu ra từ sigmoid sẽ là một vector xác suất, mỗi phần tử cho thấy khả năng lỗi của từng service, và ngưỡng (threshold) có thể được đặt để quyết định một service có lỗi hay không (ví dụ, nếu xác suất > 0.5 thì coi là có lỗi).\n",
    "\n",
    "Một vài mô hình tiêu biểu có thể kể đến:\n",
    "1. Mạng LSTM (Long Short-Term Memory) (thuộc họ RNN)\n",
    "- Kiến trúc: LSTM là một dạng của Recurrent Neural Network (RNN) có khả năng ghi nhớ các mối quan hệ dài hạn trong dữ liệu chuỗi thời gian (time-series).\n",
    "- Ứng dụng: Phù hợp cho các bài toán phân loại nhị phân và đa nhãn với dữ liệu chuỗi thời gian, như phát hiện lỗi hệ thống theo thời gian.\n",
    "- Cách hoạt động: Lớp LSTM sẽ xử lý các chuỗi dữ liệu, và lớp đầu ra sigmoid sẽ đưa ra xác suất cho từng nhãn hoặc một nhãn duy nhất (trong trường hợp phân loại nhị phân).\n",
    "\n",
    "2. Mạng CNN (Convolutional Neural Network)\n",
    "- Kiến trúc: CNN thường được dùng để nhận diện mẫu trong dữ liệu hình ảnh, nhưng cũng có thể áp dụng cho dữ liệu chuỗi với các biến đổi phù hợp.\n",
    "- Ứng dụng: CNN với sigmoid ở ngõ ra phù hợp cho các bài toán như phân loại nhãn trong hình ảnh hoặc chuỗi sự kiện.\n",
    "- Cách hoạt động: Sau khi qua các lớp tích chập (convolutional layers), các đặc trưng được xử lý qua các lớp fully connected và đầu ra sigmoid để dự đoán xác suất của từng nhãn.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NiQVGlMlhUJl"
   },
   "source": [
    "## c. Giới thiệu multi-label ở sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FQ7oh_DvhUJl"
   },
   "source": [
    "<div style=\"text-align: justify\">\n",
    "Trong Scikit-learn, phân loại multi-label là một dạng bài toán phân loại mà mỗi đối tượng (điểm dữ liệu) có thể thuộc về nhiều nhãn (label) cùng một lúc. Khác với phân loại đơn nhãn (single-label), trong đó mỗi đối tượng chỉ thuộc về một lớp duy nhất, phân loại multi-label cho phép một đối tượng có một tập hợp các nhãn. Điều này phù hợp với các tình huống mà một mẫu có thể liên quan đến nhiều danh mục, như gán thẻ cho dự đoán lỗi của nhiều dịch vụ trong hệ thống.\n",
    "\n",
    "**Cách tiếp cận multi-label trong Scikit-learn:** Scikit-learn cung cấp các phương pháp đơn giản để thực hiện phân loại multi-label. Cụ thể:\n",
    "\n",
    "1. MultiLabelBinarizer: Đây là một bộ biến đổi (transformer) để chuyển đổi nhãn thành dạng nhị phân, phù hợp với các mô hình trong Scikit-learn. Mỗi nhãn sẽ được biểu diễn dưới dạng một vector nhị phân, trong đó mỗi vị trí trong vector thể hiện sự có mặt hay vắng mặt của một nhãn.\n",
    "\n",
    "2. OneVsRestClassifier (OvR): Đây là wrapper cho phép sử dụng các mô hình phân loại đơn nhãn (như LogisticRegression, SVC) để huấn luyện thành mô hình multi-label. Phương pháp này hoạt động bằng cách tạo một bộ phân loại riêng cho từng nhãn, mỗi bộ phân loại sẽ dự đoán xem một nhãn cụ thể có hiện diện hay không.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EpLKFi9QhUJl"
   },
   "source": [
    "# 6. Giới thiệu các đặc trưng có thể rút trích từ observation (2 điểm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BnuNEpq2hUJl"
   },
   "source": [
    "## Các đặc trưng có thể rút trích: period và data của mỗi service tại các thời điểm khác nhau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dDVihecAhUJl"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def extract_features_from_observation(observation, fixed_columns=None):\n",
    "    \"\"\"\n",
    "    Tối ưu hóa trích xuất đặc trưng từ một observation.\n",
    "    \n",
    "    Args:\n",
    "        observation (DataFrame): Observation bao gồm các đặc trưng của các dịch vụ qua các bước thời gian.\n",
    "        fixed_columns (dict): Tùy chọn để trích xuất đặc trưng từ các cột cố định.\n",
    "\n",
    "    Returns:\n",
    "        np.array: Vector đặc trưng đã trích xuất từ observation.\n",
    "    \"\"\"\n",
    "    features = []\n",
    "    \n",
    "    # Nếu sử dụng cột cố định (kịch bản cụ thể)\n",
    "    if fixed_columns:\n",
    "        # Trích xuất đặc trưng cuối cùng cho các cột period\n",
    "        if \"period\" in fixed_columns:\n",
    "            period_features = observation.filter(items=fixed_columns[\"period\"]).iloc[-1].values\n",
    "            features.append(period_features)\n",
    "        \n",
    "        # Trích xuất đặc trưng cuối cùng cho các cột data\n",
    "        if \"data\" in fixed_columns:\n",
    "            data_features = observation.filter(items=fixed_columns[\"data\"]).iloc[-1].values\n",
    "            features.append(data_features)\n",
    "    else:\n",
    "        # Tự động trích xuất đặc trưng toàn diện cho dữ liệu số\n",
    "        observation_numeric = observation.select_dtypes(include=[np.number])\n",
    "\n",
    "        # Trung bình\n",
    "        features.append(observation_numeric.mean().values)\n",
    "        \n",
    "        # Độ lệch chuẩn\n",
    "        features.append(observation_numeric.std().values)\n",
    "        \n",
    "        # Xu hướng (chênh lệch giữa giá trị đầu và cuối)\n",
    "        trend = observation_numeric.iloc[-1].values - observation_numeric.iloc[0].values\n",
    "        features.append(trend)\n",
    "        \n",
    "        # Trung bình di động (window = 3)\n",
    "        if len(observation_numeric) >= 3:  # Đảm bảo đủ dữ liệu để tính rolling\n",
    "            moving_average = observation_numeric.rolling(window=3).mean().iloc[-1].values\n",
    "            features.append(moving_average)\n",
    "        \n",
    "        # Tổng tích lũy\n",
    "        features.append(observation_numeric.sum().values)\n",
    "    \n",
    "    # Kết hợp tất cả các đặc trưng\n",
    "    return np.concatenate(features)\n",
    "\n",
    "def create_feature_matrix(data, input_size, label_size, offset):\n",
    "    \"\"\"\n",
    "    Tạo ma trận đặc trưng và nhãn từ các observations.\n",
    "\n",
    "    Args:\n",
    "        data (DataFrame): Dữ liệu đã chuẩn bị với các đặc trưng của các dịch vụ.\n",
    "        input_size (int): Số bước thời gian đầu vào cho mỗi observation.\n",
    "        label_size (int): Số nhãn cần dự đoán.\n",
    "        offset (int): Khoảng cách giữa observation và thời điểm bắt đầu dự đoán.\n",
    "\n",
    "    Returns:\n",
    "        Tuple (np.array, np.array): \n",
    "            - X_features: Mảng các đặc trưng đầu vào đã trích xuất từ observations.\n",
    "            - y_labels: Mảng các nhãn multi-label với kích thước (x, 12).\n",
    "    \"\"\"\n",
    "    X_features = []\n",
    "    y_labels = []\n",
    "    \n",
    "    # Tạo các chỉ số đầu và cuối cho việc lặp qua dữ liệu\n",
    "    start_idx = input_size + offset\n",
    "    end_idx = len(data) - label_size + 1\n",
    "    \n",
    "    for i in range(start_idx, end_idx):\n",
    "        # Lấy một observation cho input_size bước thời gian\n",
    "        observation = data.iloc[i - input_size - offset : i - offset]\n",
    "        \n",
    "        # Trích xuất đặc trưng từ observation\n",
    "        features = extract_features_from_observation(observation)\n",
    "        X_features.append(features)\n",
    "        \n",
    "        # Lấy nhãn multi-label cho label_size bước thời gian\n",
    "        labels = data.iloc[i + label_size - 1][[f\"error_service_{j}\" for j in range(12)]].values\n",
    "        y_labels.append(labels)\n",
    "    \n",
    "    # Chuyển danh sách thành mảng numpy\n",
    "    X_features = np.array(X_features)\n",
    "    y_labels = np.array(y_labels)\n",
    "    \n",
    "    return X_features, y_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thiết lập các tham số\n",
    "input_size = 24  # Số bước thời gian đầu vào\n",
    "label_size = 12  # Số nhãn cần dự đoán\n",
    "offset = 12       # Khoảng cách giữa observation và thời điểm dự đoán \n",
    "\n",
    "# Tạo ma trận đặc trưng và nhãn từ dữ liệu huấn luyện và kiểm tra\n",
    "X_train, y_train = create_feature_matrix(train_data, input_size, label_size, offset)\n",
    "X_test, y_test = create_feature_matrix(test_data, input_size, label_size, offset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sUjHpVSshUJl"
   },
   "source": [
    "# 7. Giới thiệu model sử dụng (2 điểm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W2hgNgskhUJl"
   },
   "source": [
    "## a. Model được chọn là LSTM, là model Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lP_MXwpThUJl"
   },
   "source": [
    "<div style=\"text-align: justify\">\n",
    "\n",
    "**LSTM (Long Short-Term Memory)** là một loại mạng nơ-ron hồi quy (RNN) có cấu trúc đặc biệt giúp lưu trữ và cập nhật thông tin một cách hiệu quả qua nhiều bước thời gian. Khi sử dụng LSTM cho các bài toán phân loại nhị phân (multi-label), ta thường cấu hình ngõ ra (output layer) với một lớp Dense có hàm kích hoạt (activation function) là sigmoid. Hàm sigmoid giúp chuẩn hóa đầu ra về khoảng giá trị từ 0 đến 1, tương ứng với xác suất cho mỗi nhãn (label).\n",
    "\n",
    "**Cấu trúc của một mô hình LSTM điển hình với ngõ ra sử dụng sigmoid:**\n",
    "1. Lớp LSTM: Xử lý dữ liệu tuần tự, lưu giữ thông tin trong nhiều bước thời gian.\n",
    "2. Lớp Dropout: Giảm thiểu overfitting bằng cách ngẫu nhiên bỏ đi một phần các kết nối trong quá trình huấn luyện.\n",
    "3. Lớp Dense với hàm kích hoạt sigmoid: Chuẩn hóa đầu ra, để có giá trị xác suất cho mỗi nhãn.\n",
    "\n",
    "Dữ liệu đầu vào tại mỗi bước được xử lý qua các cổng. Các cổng hoạt động như những bộ lọc, cho phép mô hình giữ lại hoặc quên thông tin. Kết quả cuối cùng là đầu ra và trạng thái được cập nhật cho bước tiếp theo.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chuyển đổi thành TensorDataset và DataLoader để dùng cho mô hình\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "train_loader = DataLoader(TensorDataset(torch.tensor(X_train, dtype=torch.float32), torch.tensor(y_train, dtype=torch.float32)), batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(TensorDataset(torch.tensor(X_test, dtype=torch.float32), torch.tensor(y_test, dtype=torch.float32)), batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "vPpnPyTmhUJl"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, num_layers=2, dropout=0.4):\n",
    "        \"\"\"\n",
    "        Mô hình LSTM cho bài toán multi-label classification.\n",
    "\n",
    "        Args:\n",
    "            input_dim (int): Số lượng đặc trưng đầu vào.\n",
    "            hidden_dim (int): Số chiều của trạng thái ẩn trong LSTM.\n",
    "            output_dim (int): Số lượng nhãn đầu ra (multi-label).\n",
    "            num_layers (int): Số lớp LSTM (mặc định là 1).\n",
    "        \"\"\"\n",
    "\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True, dropout=dropout)\n",
    "        # Lớp Fully Connected để chuyển từ hidden_dim sang output_dim (12 nhãn đầu ra)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Hàm lan truyền tiến (forward) của mô hình.\n",
    "\n",
    "        Args:\n",
    "            x (Tensor): Đầu vào có kích thước [batch_size, sequence_length, input_dim].\n",
    "\n",
    "        Returns:\n",
    "            Tensor: Xác suất dự đoán cho từng nhãn với kích thước [batch_size, output_dim].\n",
    "        \"\"\"\n",
    "\n",
    "        # Đầu vào cho LSTM có dạng [batch_size, sequence_length, input_dim]\n",
    "        lstm_out, _ = self.lstm(x)  # lstm_out có kích thước [batch_size, sequence_length, hidden_dim]\n",
    "\n",
    "        if lstm_out.dim() == 3 and lstm_out.size(1) >= 2:\n",
    "            # Lấy hai bước thời gian cuối cùng nếu có đủ chiều\n",
    "            last_two_steps = lstm_out[:, -2:, :]  # Kích thước [batch_size, 2, hidden_dim]\n",
    "            mean_last_two = last_two_steps.mean(dim=1)  # Tính trung bình của 2 bước cuối cùng, kích thước [batch_size, hidden_dim]\n",
    "        else:\n",
    "            # Nếu lstm_out không đủ chiều hoặc chỉ có 1 bước thời gian\n",
    "            mean_last_two = lstm_out.mean(dim=1)  # Tính trung bình tất cả các bước thời gian, kích thước [batch_size, hidden_dim]\n",
    "\n",
    "        # Đưa qua lớp fully connected để có 12 nhãn đầu ra\n",
    "        out = self.fc(mean_last_two)  # Kích thước [batch_size, output_dim]\n",
    "        return self.sigmoid(out)  # Dự đoán xác suất cho mỗi nhãn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "K23tzoGmhUJl"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Thiết lập tham số cho mô hình\n",
    "input_dim = X_train.shape[1]  # Số đặc trưng đầu vào\n",
    "hidden_dim = 64               # Số chiều của trạng thái ẩn\n",
    "output_dim = 12               # Số nhãn đầu ra (multi-label)\n",
    "num_layers = 1                # Số lớp LSTM\n",
    "dropout = 0.5\n",
    "\n",
    "# Khởi tạo mô hình\n",
    "model = LSTMModel(input_dim=input_dim, hidden_dim=hidden_dim, output_dim=output_dim, num_layers=num_layers, dropout=dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "\n",
    "# Thiết lập các tham số huấn luyện\n",
    "num_epochs = 20\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Hàm mất mát và tối ưu hóa\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Huấn luyện mô hình\n",
    "def train_model(model, train_loader, criterion, optimizer, num_epochs):\n",
    "    \"\"\"\n",
    "    Huấn luyện mô hình với dữ liệu từ train_loader.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): Mô hình cần huấn luyện.\n",
    "        train_loader (DataLoader): DataLoader cung cấp các batch dữ liệu huấn luyện.\n",
    "        criterion (nn.Module): Hàm tính toán mất mát.\n",
    "        optimizer (torch.optim.Optimizer): Bộ tối ưu hóa.\n",
    "        num_epochs (int): Số epoch huấn luyện.\n",
    "    \"\"\"\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            # Nếu X_batch có kích thước [batch_size, input_dim], thêm chiều cho sequence_length\n",
    "            if X_batch.dim() == 2:\n",
    "                X_batch = X_batch.unsqueeze(1)  # Thêm chiều sequence_length, kích thước [batch_size, 1, input_dim]\n",
    "\n",
    "            # Đặt lại gradient về 0\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Dự đoán\n",
    "            outputs = model(X_batch)\n",
    "\n",
    "            # Tính toán mất mát\n",
    "            loss = criterion(outputs, y_batch)\n",
    "\n",
    "            # Lan truyền ngược và cập nhật trọng số\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Cộng dồn mất mát\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        # In mất mát mỗi epoch\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 0.24235596941554383\n",
      "Epoch [2/20], Loss: 0.07593145216368649\n",
      "Epoch [3/20], Loss: 0.06688178685327915\n",
      "Epoch [4/20], Loss: 0.06373160495741727\n",
      "Epoch [5/20], Loss: 0.06177677402961744\n",
      "Epoch [6/20], Loss: 0.06049089006161037\n",
      "Epoch [7/20], Loss: 0.059422783451537564\n",
      "Epoch [8/20], Loss: 0.05853942516323638\n",
      "Epoch [9/20], Loss: 0.05761556220177102\n",
      "Epoch [10/20], Loss: 0.05680596453380095\n",
      "Epoch [11/20], Loss: 0.05581557299074245\n",
      "Epoch [12/20], Loss: 0.05514788719480985\n",
      "Epoch [13/20], Loss: 0.0544114099968582\n",
      "Epoch [14/20], Loss: 0.053595572454880364\n",
      "Epoch [15/20], Loss: 0.05282261847735268\n",
      "Epoch [16/20], Loss: 0.052235697345068194\n",
      "Epoch [17/20], Loss: 0.05138949535736074\n",
      "Epoch [18/20], Loss: 0.05064332585985938\n",
      "Epoch [19/20], Loss: 0.04994019835370861\n",
      "Epoch [20/20], Loss: 0.049095659810182164\n"
     ]
    }
   ],
   "source": [
    "# Gọi hàm huấn luyện\n",
    "train_model(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    num_epochs=num_epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g9fXWPUmhUJm"
   },
   "source": [
    "## b. Input - Output của model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2REoaOx2hUJm"
   },
   "source": [
    "**Phương pháp sử dụng: Multivariate to Multivariate**\n",
    "\n",
    "**Input**\n",
    "- Kích thước: (batch_size, sequence_length, input_dim).\n",
    "- Giải thích:\n",
    "    + batch_size: Số lượng observation trong mỗi batch (định nghĩa khi tạo DataLoader, ví dụ: 64).\n",
    "    + sequence_length: Số bước thời gian trong mỗi observation (cũng chính là input_size, ví dụ: 24 giờ).\n",
    "    + input_dim: Số lượng đặc trưng được rút trích từ mỗi observation, bao gồm các đặc trưng như trung bình, xu hướng, biến động, v.v., từ 24 đặc trưng ban đầu.\n",
    "    \n",
    "Ví dụ: nếu sequence_length là 12 và có 24 đặc trưng rút trích, thì đầu vào cho mỗi observation sẽ có kích thước (12, 24).\n",
    "\n",
    "**Output**\n",
    "- Kích thước: (batch_size, output_dim).\n",
    "- Giải thích:\n",
    "    + output_dim là số lượng nhãn cần dự đoán (ở đây là 12 nhãn, mỗi nhãn tương ứng với error_flag của từng dịch vụ).\n",
    "    + Mỗi giá trị trong đầu ra là xác suất dịch vụ sẽ gặp lỗi (error_flag = 1) trong 2 giờ tới."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9wkk4N5LhUJm"
   },
   "source": [
    "## c. Phương trình thể hiện mối liên hệ giữa input - output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S7GtFbnYhUJm"
   },
   "source": [
    "### Trạng thái ẩn của LSTM:\n",
    "- Mỗi bước thời gian \\( t \\) của chuỗi đầu vào sẽ tạo ra một trạng thái ẩn \\( h_t \\) và một trạng thái ô nhớ \\( c_t \\) qua công thức sau:\n",
    "  $$\n",
    "  h_t, c_t = \\text{LSTM}(x_t, (h_{t-1}, c_{t-1}))\n",
    "  $$\n",
    "  - \\( x_t \\): đầu vào của LSTM tại bước thời gian \\( t \\), với kích thước là input_dim.\n",
    "  - \\( h_t \\): trạng thái ẩn tại bước \\( t \\), đại diện cho thông tin tích lũy từ bước đầu đến bước \\( t \\).\n",
    "  - \\( c_t \\): trạng thái ô nhớ tại bước \\( t \\), lưu trữ thông tin dài hạn trong chuỗi.\n",
    "\n",
    "### Lớp Fully Connected:\n",
    "- Sau khi LSTM xử lý hết chuỗi thời gian (tức là toàn bộ sequence_length), trạng thái ẩn của bước thời gian cuối cùng, \\( h_T \\), được sử dụng để dự đoán xác suất lỗi của các dịch vụ.\n",
    "- Công thức cho lớp fully connected như sau:\n",
    "  $$\n",
    "  y = \\text{Sigmoid}(W h_T + b)\n",
    "  $$\n",
    "  - \\( h_T \\): trạng thái ẩn của LSTM tại bước thời gian cuối cùng của chuỗi đầu vào.\n",
    "  - \\( W \\): ma trận trọng số của lớp fully connected, có kích thước (hidden_dim, output_dim), để chuyển từ hidden_dim sang output_dim.\n",
    "  - \\( b \\): vector độ chệch của lớp fully connected.\n",
    "  - Sigmoid: Hàm kích hoạt sigmoid được áp dụng để đưa đầu ra vào khoảng \\([0, 1]\\), biểu thị xác suất.\n",
    "\n",
    "### Dự đoán đa nhãn (multi-label):\n",
    "- Đầu ra cuối cùng \\( y \\) là một vector kích thước output_dim (ở đây là 12), với mỗi phần tử \\( y_i \\) biểu thị xác suất xảy ra lỗi cho dịch vụ \\( i \\):\n",
    "  $$\n",
    "  y_i = \\text{Sigmoid}(W_i h_T + b_i)\n",
    "  $$\n",
    "  - \\( y_i \\): xác suất xảy ra lỗi của dịch vụ \\( i \\) trong 2 giờ tiếp theo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9X0wmbzmhUJm"
   },
   "source": [
    "**Kết luận quan hệ đầu vào - đầu ra trong mô hình**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pVGVrUsVhUJm"
   },
   "source": [
    "### Phương trình tổng quát:\n",
    "- Đầu vào là chuỗi các đặc trưng qua thời gian (mỗi observation dài sequence_length). Chuỗi này đi qua LSTM và tạo ra các trạng thái ẩn. Trạng thái ẩn cuối cùng \\( h_T \\) được đưa qua lớp fully connected và sigmoid để tạo ra vector đầu ra \\( y \\), biểu thị xác suất lỗi của từng dịch vụ trong thời gian tới.\n",
    "\n",
    "  $$\n",
    "  y = \\text{Sigmoid}(W h_T + b)\n",
    "  $$\n",
    "\n",
    "Trong đó \\( y \\) là đầu ra multi-label, cho biết xác suất lỗi của từng dịch vụ dựa trên chuỗi thời gian đầu vào."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WikKN5ZLhUJm"
   },
   "source": [
    "## d. Kết quả của quá trình huấn luyện"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "2sZP_PYyhUJm"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "\n",
    "def evaluate_model(model, test_loader, threshold=0.7): \n",
    "    \"\"\"\n",
    "    Đánh giá mô hình với khả năng điều chỉnh ngưỡng dự đoán và tránh sai lệch.\n",
    "    \n",
    "    Args:\n",
    "        model (nn.Module): Mô hình đã được huấn luyện.\n",
    "        test_loader (DataLoader): DataLoader chứa dữ liệu kiểm tra.\n",
    "        threshold (float): Ngưỡng dự đoán để phân loại nhị phân.\n",
    "\n",
    "    Returns:\n",
    "        dict: Chứa Accuracy, F1 Score, AUC và các dự đoán.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_probs = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in test_loader:\n",
    "            if X_batch.dim() == 2:  # Nếu chỉ có 2 chiều, thêm một chiều giả để đảm bảo tính nhất quán\n",
    "                X_batch = X_batch.unsqueeze(1)\n",
    "            \n",
    "            outputs = model(X_batch)\n",
    "            probs = torch.sigmoid(outputs)  # Chuyển logits thành xác suất\n",
    "            preds = (probs >= threshold).float()\n",
    "\n",
    "            all_probs.append(probs.cpu().numpy())\n",
    "            all_preds.append(preds.cpu().numpy())\n",
    "            all_labels.append(y_batch.cpu().numpy())\n",
    "\n",
    "    # Kết hợp tất cả các batch\n",
    "    all_probs = np.concatenate(all_probs, axis=0)\n",
    "    all_preds = np.concatenate(all_preds, axis=0)\n",
    "    all_labels = np.concatenate(all_labels, axis=0)\n",
    "\n",
    "    # Tính các chỉ số đánh giá\n",
    "    accuracy = accuracy_score(all_labels.flatten(), all_preds.flatten())\n",
    "    f1 = f1_score(all_labels.flatten(), all_preds.flatten(), average='macro')\n",
    "\n",
    "    # Tính AUC cho từng nhãn nếu đủ hai lớp\n",
    "    auc_list = []\n",
    "    for i in range(all_labels.shape[1]):\n",
    "        if len(np.unique(all_labels[:, i])) > 1:\n",
    "            auc = roc_auc_score(all_labels[:, i], all_probs[:, i])\n",
    "            auc_list.append(auc)\n",
    "    \n",
    "    mean_auc = np.mean(auc_list) if auc_list else None\n",
    "\n",
    "    # In các chỉ số đánh giá\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    if mean_auc is not None:\n",
    "        print(f\"Mean AUC: {mean_auc:.4f}\")\n",
    "    else:\n",
    "        print(\"AUC could not be calculated for any labels.\")\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"f1_score\": f1,\n",
    "        \"mean_auc\": mean_auc,\n",
    "        \"predictions\": all_preds,\n",
    "        \"probabilities\": all_probs,\n",
    "    }\n",
    "\n",
    "# Dự đoán lỗi dịch vụ\n",
    "def predict_services_with_errors(probabilities, threshold=0.7):\n",
    "    \"\"\"\n",
    "    Xác định các dịch vụ có khả năng gặp lỗi dựa trên xác suất dự đoán.\n",
    "\n",
    "    Args:\n",
    "        probabilities (numpy.array): Xác suất dự đoán từ mô hình.\n",
    "        threshold (float): Ngưỡng dự đoán để xác định lỗi.\n",
    "\n",
    "    Returns:\n",
    "        list: Danh sách các dịch vụ dự kiến gặp lỗi.\n",
    "    \"\"\"\n",
    "    predicted_labels = (probabilities >= threshold).astype(int)\n",
    "    services_with_errors = []\n",
    "\n",
    "    for i in range(predicted_labels.shape[1]):\n",
    "        if predicted_labels[:, i].sum() > 0:  \n",
    "            services_with_errors.append(i)\n",
    "    \n",
    "    if services_with_errors:\n",
    "        print(\"Dịch vụ dự kiến gặp lỗi:\", \", \".join(map(str, services_with_errors)))\n",
    "    else:\n",
    "        print(\"Không có dịch vụ nào dự kiến gặp lỗi.\")\n",
    "    \n",
    "    return services_with_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "x6tIoGpdhUJm",
    "outputId": "55f6a965-38de-4bff-9d3a-df5700f621a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9745\n",
      "F1 Score: 0.4935\n",
      "Mean AUC: 0.5912\n",
      "Không có dịch vụ nào dự kiến gặp lỗi.\n"
     ]
    }
   ],
   "source": [
    "# Đánh giá mô hình và dự đoán với ngưỡng tuỳ chỉnh\n",
    "results = evaluate_model(model, test_loader, threshold=0.8)  \n",
    "\n",
    "if results is not None:\n",
    "    # Dự đoán lỗi dịch vụ trong 2 giờ tới\n",
    "    predict_services_with_errors(results[\"probabilities\"], threshold=0.8)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JsvfzCsqhUJn"
   },
   "source": [
    "## e. Ta có thể dùng những tham số điều khiển nào? Ảnh hưởng của các tham số điều khiển đó"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3aiFkLdFhUJn"
   },
   "source": [
    "<div style=\"text-align: justify\">\n",
    "Khi xây dựng và huấn luyện mô hình LSTM cho bài toán dự đoán lỗi trong các dịch vụ, có nhiều tham số điều khiển mà bạn có thể điều chỉnh để tối ưu hóa hiệu suất của mô hình. Dưới đây là một số tham số chính và ảnh hưởng của chúng:\n",
    "\n",
    "**1. Số chiều của trạng thái ẩn (hidden_dim)**\n",
    "- Mô tả: Đây là số lượng đơn vị trong lớp LSTM.\n",
    "- Ảnh hưởng:\n",
    "    + Thấp: Nếu giá trị này quá thấp, mô hình có thể không đủ sức mạnh để học các mẫu phức tạp trong dữ liệu.\n",
    "    + Cao: Nếu quá cao, mô hình có thể học quá nhiều và dẫn đến hiện tượng overfitting, tức là hiệu suất trên tập huấn luyện tốt nhưng kém trên tập kiểm tra.\n",
    "\n",
    "**2. Số lớp LSTM (num_layers)**\n",
    "- Mô tả: Số lượng lớp LSTM xếp chồng lên nhau.\n",
    "- Ảnh hưởng:\n",
    "    + Ít lớp: Có thể không đủ sức mạnh để nắm bắt các đặc trưng phức tạp trong dữ liệu.\n",
    "    + Nhiều lớp: Có thể cải thiện khả năng học nhưng cũng có nguy cơ overfitting và tăng thời gian huấn luyện.\n",
    "\n",
    "**3. Kích thước batch (batch_size)**\n",
    "- Mô tả: Số lượng mẫu được xử lý cùng một lúc trong mỗi lần huấn luyện.\n",
    "- Ảnh hưởng:\n",
    "    + Nhỏ: Thời gian huấn luyện có thể dài hơn và có thể dẫn đến các cập nhật trọng số không ổn định.\n",
    "    + Lớn: Huấn luyện nhanh hơn và có thể ổn định hơn, nhưng cần nhiều bộ nhớ và có thể làm mất đi một số thông tin chi tiết từ dữ liệu.\n",
    "\n",
    "**4. Tốc độ học (learning_rate)**\n",
    "- Mô tả: Hệ số điều chỉnh trọng số trong quá trình huấn luyện.\n",
    "- Ảnh hưởng:\n",
    "    + Thấp: Huấn luyện có thể rất chậm, và có thể không hội tụ tới điểm tối ưu.\n",
    "    + Cao: Có thể dẫn đến việc nhảy ra khỏi điểm tối ưu, làm cho mô hình không hội tụ.\n",
    "\n",
    "**5. Số epoch (num_epochs)**\n",
    "- Mô tả: Số lần toàn bộ tập huấn luyện được đi qua trong quá trình huấn luyện.\n",
    "- Ảnh hưởng:\n",
    "    + Ít epoch: Có thể dẫn đến mô hình chưa được huấn luyện đủ (underfitting).\n",
    "    + Nhiều epoch: Có thể dẫn đến overfitting, nơi mô hình học quá nhiều chi tiết và nhiễu trong dữ liệu huấn luyện.\n",
    "\n",
    "**6. Kích thước của input (input_size)**\n",
    "- Mô tả: Số bước thời gian mà mô hình sẽ xem xét cho mỗi lần dự đoán.\n",
    "- Ảnh hưởng:\n",
    "    + Ngắn: Mô hình có thể không có đủ thông tin lịch sử để đưa ra dự đoán chính xác.\n",
    "    + Dài: Có thể cung cấp thông tin phong phú hơn nhưng cũng có thể làm cho mô hình khó học hơn và làm tăng thời gian tính toán.\n",
    "\n",
    "Mỗi tham số điều khiển có vai trò quan trọng và có thể ảnh hưởng lớn đến hiệu suất của mô hình. Việc lựa chọn và tối ưu hóa các tham số này thường yêu cầu thử nghiệm và điều chỉnh (hyperparameter tuning) để đạt được kết quả tốt nhất cho bài toán.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0JYkwN2RhUJn"
   },
   "source": [
    "# 8. Giới thiệu metric đánh giá cho bài toán multi-label (1 điểm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E8q2MjqphUJn"
   },
   "source": [
    "Đối với bài toán multi-label classification (phân loại đa nhãn), mỗi mẫu có thể được gán với nhiều nhãn (labels), và việc đánh giá mô hình sẽ phức tạp hơn so với các bài toán phân loại nhị phân hay phân loại đơn nhãn. Các metric phổ biến được sử dụng trong multi-label classification bao gồm:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CPacEsmXhUJn"
   },
   "source": [
    "## a. ACC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t658Tb4ghUJn"
   },
   "source": [
    "Trong bài toán multi-label, Accuracy có thể được tính theo cách đo độ chính xác toàn cục, tức là tỷ lệ nhãn được dự đoán chính xác trên tổng số nhãn. Do mô hình cần đưa ra nhiều nhãn (một nhãn cho mỗi dịch vụ), nên Accuracy đo lường mức độ chính xác trung bình trên các nhãn.\n",
    "Công thức tính Accuracy cho multi-label classification:\n",
    "\n",
    "### Độ chính xác (Accuracy)\n",
    "$$\n",
    "\\text{Accuracy} = \\frac{1}{N} \\sum_{i=1}^{N} \\frac{|Y_i \\cap \\hat{Y_i}|}{|Y_i \\cup \\hat{Y_i}|}\n",
    "$$\n",
    "\n",
    "- \\( N \\): Tổng số mẫu trong tập dữ liệu.\n",
    "- \\( Y_i \\): Tập nhãn thực tế của mẫu thứ \\( i \\).\n",
    "- \\( \\hat{Y_i} \\): Tập nhãn được mô hình dự đoán cho mẫu thứ \\( i \\).\n",
    "- \\( |Y_i \\cap \\hat{Y_i}| \\): Số lượng nhãn mà mô hình dự đoán đúng cho mẫu \\( i \\).\n",
    "- \\( |Y_i \\cup \\hat{Y_i}| \\): Tổng số nhãn thực tế và dự đoán (bao gồm cả nhãn dự đoán đúng và sai) của mẫu \\( i \\).\n",
    "\n",
    "- Accuracy là một chỉ số tổng quan, phản ánh khả năng của mô hình trong việc đưa ra dự đoán chính xác cho tất cả các dịch vụ.\n",
    "- Với kết quả của bạn là Accuracy = 0.9602, mô hình có độ chính xác khá cao trong việc dự đoán lỗi của các dịch vụ. Tuy nhiên, vì Accuracy không phản ánh tốt trong trường hợp dữ liệu mất cân bằng, cần kết hợp với các chỉ số khác để đánh giá toàn diện."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HLYXPuP8hUJn"
   },
   "source": [
    "## b. F1 Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u-C6iMNmhUJn"
   },
   "source": [
    "F1 Score là trung bình điều hòa giữa Precision và Recall, giúp cân bằng giữa hai chỉ số này, đặc biệt hữu ích khi dữ liệu có sự mất cân bằng giữa nhãn lỗi và không lỗi.\n",
    "\n",
    "$$\n",
    "\\text{F1-score} = \\frac{2 \\cdot \\text{Precision} \\cdot \\text{Recall}}{\\text{Precision} + \\text{Recall}}\n",
    "$$\n",
    "\n",
    "Trong đó:\n",
    "- **Precision** (Độ chính xác): Là tỷ lệ giữa số lượng dự đoán đúng (True Positives) trong số tất cả các dự đoán dương tính. Precision thể hiện mức độ mà các dự đoán dương tính của mô hình là chính xác.\n",
    "  $$\n",
    "  \\text{Precision} = \\frac{\\text{True Positives}}{\\text{True Positives} + \\text{False Positives}}\n",
    "  $$\n",
    "\n",
    "- **Recall** (Độ nhạy): Là tỷ lệ giữa số lượng dự đoán đúng (True Positives) trong số tất cả các trường hợp thực sự dương tính. Recall thể hiện khả năng của mô hình trong việc phát hiện các trường hợp dương tính.\n",
    "  $$\n",
    "  \\text{Recall} = \\frac{\\text{True Positives}}{\\text{True Positives} + \\text{False Negatives}}\n",
    "  $$\n",
    "\n",
    "- F1 Score đo lường sự chính xác của mô hình trong việc dự đoán các dịch vụ lỗi, đồng thời đảm bảo không bỏ sót lỗi nào.\n",
    "- F1 Score của bạn là 0.5347, cho thấy mô hình chưa tối ưu trong việc cân bằng giữa Precision và Recall. Điều này có thể có nghĩa là mô hình đang bỏ sót một số lỗi hoặc gặp khó khăn trong việc phân biệt dịch vụ lỗi với không lỗi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n8IB8c3XhUJn"
   },
   "source": [
    "## c. AUC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QVhKaCf7hUJn"
   },
   "source": [
    "AUC là diện tích dưới đường cong ROC, phản ánh khả năng phân biệt của mô hình giữa các nhãn. Trong bài toán multi-label, AUC được tính trung bình cho tất cả các nhãn.\n",
    "\n",
    "### AUC (Area Under the Curve)\n",
    "AUC (Area Under the Curve) là thước đo đánh giá hiệu suất của mô hình trong các bài toán phân loại, đặc biệt là các mô hình phân loại nhị phân. AUC là diện tích dưới đường cong ROC (Receiver Operating Characteristic), thể hiện khả năng phân tách giữa các lớp.\n",
    "\n",
    "#### Giá trị AUC\n",
    "- **AUC = 1**: Mô hình hoàn hảo, có khả năng phân loại chính xác tất cả các trường hợp.\n",
    "- **AUC = 0.5**: Mô hình không có khả năng phân loại, tương đương với đoán ngẫu nhiên.\n",
    "- **0.5 < AUC < 1**: Mô hình có hiệu suất tốt, giá trị AUC càng cao, mô hình càng có khả năng phân biệt tốt giữa các lớp.\n",
    "\n",
    "- AUC giúp đánh giá khả năng phân biệt dịch vụ lỗi và không lỗi. Giá trị AUC gần 1 cho thấy mô hình có thể phân biệt tốt giữa các dịch vụ lỗi và không lỗi.\n",
    "- Với AUC = 0.5026, mô hình chưa phân biệt tốt giữa các nhãn. Giá trị này gần 0.5, nghĩa là mô hình hoạt động xấp xỉ ngẫu nhiên trong việc dự đoán lỗi, nên cần cải tiến thêm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gWxFZ-UIhUJn"
   },
   "source": [
    "# 9. Thí nghiệm (1 điểm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v3S2TxlfhUJn"
   },
   "source": [
    "Có thể áp dụng các kỹ thuật như hyperparameter tuning, thay đổi kiến trúc mô hình, hoặc xử lý dữ liệu mất cân bằng để cải thiện F1 Score và AUC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WDts_PQahUJn"
   },
   "source": [
    "## a. Chạy thí nghiệm với các hyperparameter tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TnHBBqL4hUJn"
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "import numpy as np\n",
    "\n",
    "# Định nghĩa mô hình LSTM\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, num_layers=2, dropout=0.5):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True, dropout=(dropout if num_layers > 1 else 0))\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        \n",
    "        # Nếu chuỗi có ít hơn 2 bước thời gian, tính trung bình tất cả các bước thời gian\n",
    "        if lstm_out.size(1) == 1:\n",
    "            mean_last_two = lstm_out.mean(dim=1)  # Tính trung bình cho các bước thời gian (sequence length = 1)\n",
    "        else:\n",
    "            mean_last_two = lstm_out[:, -2:, :].mean(dim=1)  # Nếu có nhiều hơn 1 bước, tính trung bình hai bước cuối\n",
    "        \n",
    "        out = self.fc(mean_last_two)\n",
    "        return torch.sigmoid(out)\n",
    "\n",
    "# Định nghĩa các giá trị hyperparameters để thử nghiệm\n",
    "hidden_dims = [32, 64, 100]\n",
    "num_layers_list = [1, 2]\n",
    "learning_rates = [0.001, 0.01]\n",
    "\n",
    "# Hàm huấn luyện mô hình\n",
    "def train_model(model, train_loader, criterion, optimizer, num_epochs=30):\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for inputs, labels in train_loader:\n",
    "            # Kiểm tra và điều chỉnh kích thước của dữ liệu\n",
    "            if inputs.dim() == 2:  # Nếu chỉ có 1 bước thời gian\n",
    "                inputs = inputs.unsqueeze(1)  # Thêm chiều sequence_length\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "\n",
    "def evaluate_model(model, test_loader, threshold=0.65):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_probs = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in test_loader:\n",
    "            # Đảm bảo đầu vào có đúng kích thước (batch_size, sequence_length, input_dim)\n",
    "            if X_batch.dim() == 2:  # Chỉ có 1 bước thời gian\n",
    "                X_batch = X_batch.unsqueeze(1)  # Thêm chiều sequence_length\n",
    "\n",
    "            outputs = model(X_batch)\n",
    "            probs = torch.sigmoid(outputs)\n",
    "            preds = (probs >= threshold).float()\n",
    "\n",
    "            all_probs.append(probs.cpu().numpy())\n",
    "            all_preds.append(preds.cpu().numpy())\n",
    "            all_labels.append(y_batch.cpu().numpy())\n",
    "\n",
    "    all_probs = np.concatenate(all_probs, axis=0)\n",
    "    all_preds = np.concatenate(all_preds, axis=0)\n",
    "    all_labels = np.concatenate(all_labels, axis=0)\n",
    "\n",
    "    return all_labels, all_preds, all_probs\n",
    "\n",
    "# Chạy thí nghiệm với các hyperparameter tuning\n",
    "def run_experiments(input_dim, output_dim, train_loader, test_loader):\n",
    "    best_score = -1\n",
    "    best_params = None\n",
    "    best_model = None\n",
    "\n",
    "    for hidden_dim, num_layers, learning_rate in itertools.product(hidden_dims, num_layers_list, learning_rates):\n",
    "        print(f\"\\nTraining with hidden_dim={hidden_dim}, num_layers={num_layers}, learning_rate={learning_rate}\")\n",
    "\n",
    "        # Khởi tạo mô hình với các tham số hiện tại\n",
    "        model = LSTMModel(input_dim=input_dim, hidden_dim=hidden_dim, output_dim=output_dim, num_layers=num_layers)\n",
    "\n",
    "        # Định nghĩa hàm mất mát và tối ưu hóa\n",
    "        criterion = nn.BCELoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "        # Huấn luyện mô hình\n",
    "        train_model(model, train_loader, criterion, optimizer)\n",
    "        \n",
    "        # Đánh giá mô hình và lưu dự đoán\n",
    "        y_true, y_pred, y_prob = evaluate_model(model, test_loader)\n",
    "\n",
    "        # Tính toán và hiển thị các chỉ số đánh giá\n",
    "        try:\n",
    "            accuracy = accuracy_score(y_true.flatten(), y_pred.flatten())\n",
    "            f1 = f1_score(y_true.flatten(), y_pred.flatten(), average='macro')\n",
    "            auc_scores = [\n",
    "                roc_auc_score(y_true[:, i], y_prob[:, i])\n",
    "                for i in range(y_prob.shape[1]) if len(np.unique(y_true[:, i])) > 1\n",
    "            ]\n",
    "            auc = np.mean(auc_scores) if auc_scores else None\n",
    "\n",
    "            print(f\"Results - Accuracy: {accuracy:.4f}, F1 Score: {f1:.4f}, AUC: {auc:.6f}\" if auc is not None else \"AUC could not be calculated\")\n",
    "\n",
    "            total_score = accuracy + f1 + (auc if auc is not None else 0)\n",
    "\n",
    "            if total_score > best_score:\n",
    "                best_score = total_score\n",
    "                best_params = {'hidden_dim': hidden_dim, 'num_layers': num_layers, 'learning_rate': learning_rate}\n",
    "                best_model = model\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error occurred during evaluation: {e}\")\n",
    "            print(f\"y_true shape: {y_true.shape}, y_pred shape: {y_pred.shape}, y_prob shape: {y_prob.shape}\")\n",
    "            continue\n",
    "\n",
    "    print(\"\\nBest Model Parameters:\")\n",
    "    print(best_params)\n",
    "    return best_model, best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d8ycHuYthUJo"
   },
   "source": [
    "## b. Report kết quả với ACC, F1 Score, AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with hidden_dim=32, num_layers=1, learning_rate=0.001\n",
      "Results - Accuracy: 0.9347, F1 Score: 0.5013, AUC: 0.540923\n",
      "\n",
      "Training with hidden_dim=32, num_layers=1, learning_rate=0.01\n",
      "Results - Accuracy: 0.9404, F1 Score: 0.5134, AUC: 0.523857\n",
      "\n",
      "Training with hidden_dim=32, num_layers=2, learning_rate=0.001\n",
      "Results - Accuracy: 0.9736, F1 Score: 0.4933, AUC: 0.632685\n",
      "\n",
      "Training with hidden_dim=32, num_layers=2, learning_rate=0.01\n",
      "Results - Accuracy: 0.9743, F1 Score: 0.4949, AUC: 0.632443\n",
      "\n",
      "Training with hidden_dim=64, num_layers=1, learning_rate=0.001\n",
      "Results - Accuracy: 0.9455, F1 Score: 0.5083, AUC: 0.596382\n",
      "\n",
      "Training with hidden_dim=64, num_layers=1, learning_rate=0.01\n",
      "Results - Accuracy: 0.9265, F1 Score: 0.5527, AUC: 0.550631\n",
      "\n",
      "Training with hidden_dim=64, num_layers=2, learning_rate=0.001\n",
      "Results - Accuracy: 0.9743, F1 Score: 0.4935, AUC: 0.613529\n",
      "\n",
      "Training with hidden_dim=64, num_layers=2, learning_rate=0.01\n",
      "Results - Accuracy: 0.9737, F1 Score: 0.4933, AUC: 0.635488\n",
      "\n",
      "Training with hidden_dim=100, num_layers=1, learning_rate=0.001\n",
      "Results - Accuracy: 0.8818, F1 Score: 0.5020, AUC: 0.578676\n",
      "\n",
      "Training with hidden_dim=100, num_layers=1, learning_rate=0.01\n",
      "Results - Accuracy: 0.9393, F1 Score: 0.5136, AUC: 0.544170\n",
      "\n",
      "Training with hidden_dim=100, num_layers=2, learning_rate=0.001\n",
      "Results - Accuracy: 0.9695, F1 Score: 0.4987, AUC: 0.583132\n",
      "\n",
      "Training with hidden_dim=100, num_layers=2, learning_rate=0.01\n",
      "Results - Accuracy: 0.9742, F1 Score: 0.4935, AUC: 0.623834\n",
      "\n",
      "Best Model Parameters:\n",
      "{'hidden_dim': 64, 'num_layers': 2, 'learning_rate': 0.01}\n",
      "Best hyperparameters: {'hidden_dim': 64, 'num_layers': 2, 'learning_rate': 0.01}\n"
     ]
    }
   ],
   "source": [
    "# Thực hiện các thí nghiệm\n",
    "best_model, best_params = run_experiments(input_dim, output_dim, train_loader=train_loader, test_loader=test_loader)\n",
    "\n",
    "# In kết quả tham số tốt nhất\n",
    "print(\"Best hyperparameters:\", best_params)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
